{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The whole approach of the notebook is described as below:\n",
    "\n",
    "1. Loading the data and categorizing the audio into one of the following labels:\n",
    "\n",
    "    ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "2. Having loaded the data, we would be resampling the audio to a sample rate of 8000, we would be mixing the audio, with the help of the background noise,and then would train the data.\n",
    "3. Reducing the dimension to 4000 (earlier it was 8000), and then observing the metrics\n",
    "4. Again, applying the cross-validation technique (on both non-reduced non-dimensional and reduced dimensional data) and , and then comparing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T18:10:38.754939Z",
     "iopub.status.busy": "2021-05-09T18:10:38.754044Z",
     "iopub.status.idle": "2021-05-09T18:12:49.907925Z",
     "shell.execute_reply": "2021-05-09T18:12:49.908485Z"
    },
    "papermill": {
     "duration": 131.168167,
     "end_time": "2021-05-09T18:12:49.908847",
     "exception": false,
     "start_time": "2021-05-09T18:10:38.740680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyunpack\r\n",
      "  Downloading pyunpack-0.2.2-py2.py3-none-any.whl (3.8 kB)\r\n",
      "Collecting easyprocess\r\n",
      "  Downloading EasyProcess-0.3-py2.py3-none-any.whl (7.9 kB)\r\n",
      "Collecting entrypoint2\r\n",
      "  Downloading entrypoint2-0.2.4-py3-none-any.whl (6.2 kB)\r\n",
      "Installing collected packages: entrypoint2, easyprocess, pyunpack\r\n",
      "Successfully installed easyprocess-0.3 entrypoint2-0.2.4 pyunpack-0.2.2\r\n",
      "Collecting patool\r\n",
      "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 77 kB 571 kB/s \r\n",
      "\u001b[?25hInstalling collected packages: patool\r\n",
      "Successfully installed patool-1.12\r\n",
      "{'marvin': 1746, 'yes': 2377, 'stop': 2380, 'go': 2372, 'six': 2369, 'left': 2353, 'down': 2359, 'on': 2367, 'tree': 1733, 'wow': 1745, 'three': 2356, 'right': 2367, 'four': 2372, 'happy': 1742, 'nine': 2364, 'seven': 2377, 'bird': 1731, 'zero': 2376, 'two': 2373, '_background_noise_': 7, 'off': 2357, 'no': 2375, 'up': 2375, 'sheila': 1734, 'bed': 1713, 'eight': 2352, 'five': 2357, 'dog': 1746, 'house': 1750, 'cat': 1733, 'one': 2370}\n"
     ]
    }
   ],
   "source": [
    "!pip install pyunpack\n",
    "!pip install patool\n",
    "# Extracting the .7z file, as the given file is in .7z format and the notebook is running on kaggle\n",
    "import os\n",
    "from pyunpack import Archive\n",
    "os.system('apt-get install p7zip')\n",
    "import shutil\n",
    "if not os.path.exists('/kaggle/working/train/'):\n",
    "    '''If already, some file is created don't make it\n",
    "    '''\n",
    "    os.makedirs('/kaggle/working/train/')\n",
    "\n",
    "# Extracting the .7z file \n",
    "Archive('../input/tensorflow-speech-recognition-challenge/train.7z').extractall('/kaggle/working/train/')\n",
    "\n",
    "\n",
    "# Checking the number of each file\n",
    "import os\n",
    "path = os.listdir('./train/train/audio/')\n",
    "size = {}\n",
    "for i in path:\n",
    "      size[i] = len(os.listdir('./train/train/audio/'+i))\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the labelled dataset\n",
    "\n",
    "Basically, we have some folders containing the audio files, in which most of them are of fixed duration (i.e of one sec), however, many of them are of the duration less than 1 sec, and the audio dataset is basically taken in a quiet place,however in real life scenario, there is a bit of background noise, and we would be mixing some percentage of background noise to the original model, to make it more robust\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T18:12:49.962555Z",
     "iopub.status.busy": "2021-05-09T18:12:49.959338Z",
     "iopub.status.idle": "2021-05-09T18:57:55.663227Z",
     "shell.execute_reply": "2021-05-09T18:57:55.663950Z"
    },
    "papermill": {
     "duration": 2705.734255,
     "end_time": "2021-05-09T18:57:55.664322",
     "exception": false,
     "start_time": "2021-05-09T18:12:49.930067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current label is: yes of: 0\n",
      "The current label is: no of: 1\n",
      "The current label is: up of: 2\n",
      "The current label is: down of: 3\n",
      "The current label is: left of: 4\n",
      "The current label is: right of: 5\n",
      "The current label is: on of: 6\n",
      "The current label is: off of: 7\n",
      "The current label is: stop of: 8\n",
      "The current label is: go of: 9\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n",
      "The current label is: unknown of: 10\n"
     ]
    }
   ],
   "source": [
    "import librosa # For loading the audio file\n",
    "\n",
    "labels_to_consider = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "unknown = [i for i in os.listdir('./train/train/audio') if i not in labels_to_consider and i != '_background_noise_' ]\n",
    "\n",
    "def label_encoder(directory):\n",
    "    '''\n",
    "    Input: labels -> list of labels to be considered\n",
    "           directory -> the folder in which the examples for all the dataset is present\n",
    "           \n",
    "    Output : list containing the entry as: (sample,gruop number)\n",
    "    '''\n",
    "    i = 0\n",
    "    label_encoder ={}\n",
    "    labelled_wave = []\n",
    "    training_data = []\n",
    "    for label in labels_to_consider:\n",
    "        path = os.path.join(directory,label)\n",
    "        label_encoder[label] = i    # Label to encoder\n",
    "        print(\"The current label is: \"+str(label)+\" of: \"+str(i))\n",
    "        i+=1\n",
    "        for audio_file in os.listdir(path):\n",
    "            if audio_file.endswith('.wav'):\n",
    "                samples, sample_rate = librosa.load(os.path.join(os.path.join(directory,label),audio_file))\n",
    "                samples = librosa.resample(samples,sample_rate,8000)\n",
    "            if len(samples)!=8000:\n",
    "                continue\n",
    "            else:\n",
    "                labelled_wave.append([samples,label])\n",
    "                training_data.append(samples)\n",
    "    for label in unknown:\n",
    "                print(\"The current label is: \"+str(\"unknown\"+\" of: \"+str(i)))\n",
    "                label_encoder['unknown'] = i\n",
    "                path = os.path.join(directory,label)\n",
    "                for audio_file in os.listdir(path):\n",
    "                    if audio_file.endswith('.wav'):\n",
    "                        samples, sample_rate = librosa.load(os.path.join(os.path.join(directory,label),audio_file))\n",
    "                        samples = librosa.resample(samples,sample_rate,8000)\n",
    "                    if len(samples)!=8000:\n",
    "                        continue\n",
    "                    else:\n",
    "                        labelled_wave.append([samples,'unknown'])\n",
    "                        training_data.append(samples)\n",
    "    return labelled_wave,training_data,label_encoder\n",
    "labelled_wave,training_data,label_encoder = label_encoder('./train/train/audio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the background noise\n",
    "\n",
    "We would be adding the random noise to all the audio files, to make it more robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T18:57:55.732744Z",
     "iopub.status.busy": "2021-05-09T18:57:55.731949Z",
     "iopub.status.idle": "2021-05-09T18:57:59.081201Z",
     "shell.execute_reply": "2021-05-09T18:57:59.081754Z"
    },
    "papermill": {
     "duration": 3.385735,
     "end_time": "2021-05-09T18:57:59.082000",
     "exception": false,
     "start_time": "2021-05-09T18:57:55.696265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "def get_random_noise():\n",
    "    ''' This function will be useful for getting the random noise\n",
    "    '''\n",
    "    audios = os.listdir('./train/train/audio/_background_noise_')\n",
    "    noise = random.randint(0,len(audios)-1)\n",
    "    noise,sr = librosa.load('./train/train/audio/_background_noise_/'+audios[noise])\n",
    "    noise = librosa.resample(noise,sr,8000)\n",
    "    start =random.randint(0,noise.shape[0]-8000-1)\n",
    "    return noise[start:start+8000]\n",
    "\n",
    "\n",
    "def mix_audio(data,ratio = 0.1):\n",
    "    ''' This function will mix the original audio with the background noise\n",
    "    '''\n",
    "    noise = get_random_noise()\n",
    "    final_data = []\n",
    "    for i,j in enumerate(data):\n",
    "        final_data.append(j + (ratio*noise))\n",
    "    return final_data\n",
    "final_data = mix_audio(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T18:57:59.179528Z",
     "iopub.status.busy": "2021-05-09T18:57:59.157741Z",
     "iopub.status.idle": "2021-05-09T18:57:59.195476Z",
     "shell.execute_reply": "2021-05-09T18:57:59.194800Z"
    },
    "papermill": {
     "duration": 0.080747,
     "end_time": "2021-05-09T18:57:59.195637",
     "exception": false,
     "start_time": "2021-05-09T18:57:59.114890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = [i[1] for i in labelled_wave]\n",
    "def remove_not_equal_length(data,labels):\n",
    "    \n",
    "    '''If some array has some inadequate length, we would remove it\n",
    "    '''\n",
    "    final_data = []\n",
    "    for i,j in zip(data,labels):\n",
    "        if len(i)!=8000:\n",
    "            continue\n",
    "        else:\n",
    "            final_data.append([i,j])\n",
    "    return final_data\n",
    "dataset = remove_not_equal_length(final_data,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T18:57:59.274096Z",
     "iopub.status.busy": "2021-05-09T18:57:59.273348Z",
     "iopub.status.idle": "2021-05-09T18:58:14.518052Z",
     "shell.execute_reply": "2021-05-09T18:58:14.518581Z"
    },
    "papermill": {
     "duration": 15.289652,
     "end_time": "2021-05-09T18:58:14.518761",
     "exception": false,
     "start_time": "2021-05-09T18:57:59.229109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Traininng data = wav_file\n",
    "# Labels = target\n",
    "wave_file = [i[0] for i in dataset]\n",
    "wave_file = np.reshape(np.array(wave_file),(-1,8000,1))\n",
    "target = [label_encoder[i[1]] for i in dataset]\n",
    "target = np.reshape(target,(-1,1))\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(wave_file,target,test_size= 0.15,random_state=98,shuffle=True)\n",
    "import keras\n",
    "y_train = keras.utils.to_categorical(y_train, len(set(labels))+1)\n",
    "y_test = keras.utils.to_categorical(y_test, len(set(labels))+1)\n",
    "training_labels = [np.argmax(i) for i in y_train]\n",
    "testing_labels = [np.argmax(i) for i in y_test]\n",
    "train  = X_train.reshape(-1,8000)\n",
    "test  = X_test.reshape(-1,8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030062,
     "end_time": "2021-05-09T18:58:14.577270",
     "exception": false,
     "start_time": "2021-05-09T18:58:14.547208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T18:58:14.640766Z",
     "iopub.status.busy": "2021-05-09T18:58:14.640100Z",
     "iopub.status.idle": "2021-05-09T18:58:14.954353Z",
     "shell.execute_reply": "2021-05-09T18:58:14.953761Z"
    },
    "papermill": {
     "duration": 0.344204,
     "end_time": "2021-05-09T18:58:14.954541",
     "exception": false,
     "start_time": "2021-05-09T18:58:14.610337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()  # default is 5\n",
    "model.fit(train,training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T18:58:15.034999Z",
     "iopub.status.busy": "2021-05-09T18:58:15.034240Z",
     "iopub.status.idle": "2021-05-09T19:02:03.837728Z",
     "shell.execute_reply": "2021-05-09T19:02:03.838154Z"
    },
    "papermill": {
     "duration": 228.846773,
     "end_time": "2021-05-09T19:02:03.838314",
     "exception": false,
     "start_time": "2021-05-09T18:58:14.991541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.04      0.05       338\n",
      "           1       0.02      0.01      0.02       307\n",
      "           2       0.06      0.04      0.05       300\n",
      "           3       0.04      0.01      0.02       336\n",
      "           4       0.05      0.03      0.03       319\n",
      "           5       0.07      0.02      0.03       306\n",
      "           6       0.10      0.02      0.03       330\n",
      "           7       0.12      0.04      0.06       310\n",
      "           8       0.06      0.02      0.02       324\n",
      "           9       0.10      0.03      0.05       323\n",
      "          10       0.65      0.86      0.74      5545\n",
      "\n",
      "    accuracy                           0.55      8738\n",
      "   macro avg       0.12      0.10      0.10      8738\n",
      "weighted avg       0.43      0.55      0.48      8738\n",
      "\n",
      "The accuracy score is: 0.5537880521858549\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score,f1_score\n",
    "print(classification_report(testing_labels,model.predict(test)))\n",
    "print(\"The accuracy score is:\",accuracy_score(testing_labels,model.predict(test)))\n",
    "#print(\"The F! score is:\",f1_score(testing_labels,classifier.predict(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023228,
     "end_time": "2021-05-09T19:02:03.885872",
     "exception": false,
     "start_time": "2021-05-09T19:02:03.862644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dimensionality Reduction (8000 -> 4000 Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:02:03.940280Z",
     "iopub.status.busy": "2021-05-09T19:02:03.939738Z",
     "iopub.status.idle": "2021-05-09T19:07:22.722342Z",
     "shell.execute_reply": "2021-05-09T19:07:22.722907Z"
    },
    "papermill": {
     "duration": 318.812958,
     "end_time": "2021-05-09T19:07:22.723113",
     "exception": false,
     "start_time": "2021-05-09T19:02:03.910155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 4000)\n",
    "train_pca = pca.fit_transform(train)\n",
    "test_pca = pca.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:07:22.793196Z",
     "iopub.status.busy": "2021-05-09T19:07:22.791863Z",
     "iopub.status.idle": "2021-05-09T19:07:22.939173Z",
     "shell.execute_reply": "2021-05-09T19:07:22.940278Z"
    },
    "papermill": {
     "duration": 0.18507,
     "end_time": "2021-05-09T19:07:22.940558",
     "exception": false,
     "start_time": "2021-05-09T19:07:22.755488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pca = KNeighborsClassifier()  # default is 5\n",
    "model_pca.fit(train_pca,training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:07:22.991349Z",
     "iopub.status.busy": "2021-05-09T19:07:22.990801Z",
     "iopub.status.idle": "2021-05-09T19:09:14.987600Z",
     "shell.execute_reply": "2021-05-09T19:09:14.987997Z"
    },
    "papermill": {
     "duration": 112.024302,
     "end_time": "2021-05-09T19:09:14.988151",
     "exception": false,
     "start_time": "2021-05-09T19:07:22.963849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.04      0.04       338\n",
      "           1       0.03      0.01      0.02       307\n",
      "           2       0.07      0.06      0.06       300\n",
      "           3       0.05      0.01      0.02       336\n",
      "           4       0.06      0.03      0.04       319\n",
      "           5       0.06      0.02      0.03       306\n",
      "           6       0.10      0.02      0.03       330\n",
      "           7       0.15      0.04      0.07       310\n",
      "           8       0.07      0.02      0.03       324\n",
      "           9       0.10      0.03      0.05       323\n",
      "          10       0.64      0.86      0.74      5545\n",
      "\n",
      "    accuracy                           0.56      8738\n",
      "   macro avg       0.12      0.10      0.10      8738\n",
      "weighted avg       0.44      0.56      0.48      8738\n",
      "\n",
      "The accuracy score is: 0.5558480201419089\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testing_labels,model_pca.predict(test_pca)))\n",
    "print(\"The accuracy score is:\",accuracy_score(testing_labels,model_pca.predict(test_pca)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028845,
     "end_time": "2021-05-09T19:09:15.042781",
     "exception": false,
     "start_time": "2021-05-09T19:09:15.013936",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cross Validation (Comparison with and without Dimensionality reduction)\n",
    "Create two datasets, with dimensionality reduction, and the other one is without dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:09:15.135822Z",
     "iopub.status.busy": "2021-05-09T19:09:15.134920Z",
     "iopub.status.idle": "2021-05-09T19:17:16.563961Z",
     "shell.execute_reply": "2021-05-09T19:17:16.564603Z"
    },
    "papermill": {
     "duration": 481.474708,
     "end_time": "2021-05-09T19:17:16.564810",
     "exception": false,
     "start_time": "2021-05-09T19:09:15.090102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56 accuracy with a standard deviation of 0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# without dimensionality reduction\n",
    "scores = cross_val_score(model, train, training_labels, cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-09T19:17:16.649412Z",
     "iopub.status.busy": "2021-05-09T19:17:16.648717Z",
     "iopub.status.idle": "2021-05-09T19:21:38.662760Z",
     "shell.execute_reply": "2021-05-09T19:21:38.663377Z"
    },
    "papermill": {
     "duration": 262.058705,
     "end_time": "2021-05-09T19:21:38.663629",
     "exception": false,
     "start_time": "2021-05-09T19:17:16.604924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56 accuracy with a standard deviation of 0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# with dimensionality reduction\n",
    "scores = cross_val_score(model_pca, train_pca, training_labels, cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.037199,
     "end_time": "2021-05-09T19:21:38.738782",
     "exception": false,
     "start_time": "2021-05-09T19:21:38.701583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4271.76112,
   "end_time": "2021-05-09T19:21:41.377417",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-09T18:10:29.616297",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
