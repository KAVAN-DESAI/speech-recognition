{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# path\nimport os\nfrom os.path import join, isdir\nfrom pathlib import Path\n\n# Scientific Math\nimport numpy as np\nfrom scipy.fftpack import fft\nfrom scipy import signal\nfrom scipy.io import wavfile\nfrom sklearn.model_selection import train_test_split\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport plotly.offline as py\nimport plotly.graph_objs as go\n\n# Deep learning\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers import Dense,Dropout,Flatten\nfrom tensorflow.keras import Input,layers\nfrom tensorflow.keras import backend as K\n\nimport random\nimport copy\nimport librosa\n\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pyunpack\n!pip install patool\n# Extracting the .7z file\nimport os\nfrom pyunpack import Archive\nos.system('apt-get install p7zip')\nimport shutil\nif not os.path.exists('/kaggle/working/train/'):\n    os.makedirs('/kaggle/working/train/')\nArchive('../input/tensorflow-speech-recognition-challenge/train.7z').extractall('/kaggle/working/train/')\n\n# Checking the number of each file\nimport os\npath = os.listdir('./train/train/audio/')\nsize = {}\nfor i in path:\n      size[i] = len(os.listdir('./train/train/audio/'+i))\nprint(size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('../input/tensorflow-speech-recognition-challenge')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_audio_path = './train/train/audio/'\nprint(os.listdir(train_audio_path))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the data\nTarget list is ['yes','no','up','down','left','right','on','off','stop','go'], unknown list is other silence will be made from '_background_noise_'\n\nTrain data's sampling rate is 16000Hz, but for making lower computation cost, we would resample it to 8000Hz\n\nAfter, training the test set will also be resample to 8000Hz","metadata":{}},{"cell_type":"code","source":"dirs = [f for f in os.listdir(train_audio_path) if isdir(join(train_audio_path,f))]\ndirs.sort()\nprint(\"Number of labels:\",len(dirs)-1)\nprint(dirs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_wave = []\nunknown_wav = []\nlabel_all = []\nlabel_value = {}\ntarget_list = ['yes','no','up','down','left','right','on','off','stop','go']\nunknown_list = [d for d in dirs if d not in target_list and d!='_background_noise_']\nprint(\"Target list : \",end = '')\nprint(target_list)\nprint(\"Unknown List : \",end = '')\nprint(unknown_list)\nprint(\"Silence : _background_noise_\")\ni = 0\nbackground = [f for f in os.listdir(join(train_audio_path,'_background_noise_')) if f.endswith('.wav')]\nbackground_noise = []\nfor wav in background:\n    samples,sample_rate = librosa.load(join(join(train_audio_path,'_background_noise_'),wav))\n    samples = librosa.resample(samples,sample_rate, 8000)\n    background_noise.append(samples)\n\nfor direct in dirs[1:]:\n    waves = [f for f in os.listdir(join(train_audio_path,direct)) if f.endswith('.wav')]\n    label_value[direct] = i\n    i+=1\n    print(str(i)+ ' : '+str(direct)+\" \",end = \"\")\n    for wav in waves:\n        samples,sample_rate = librosa.load(join(join(train_audio_path,direct),wav),sr = 16000)\n        samples = librosa.resample(samples,sample_rate,8000)\n        if len(samples)!=8000:\n            continue\n        if direct in unknown_list:\n            unknown_wav.append(samples)\n        else:\n            label_all.append(direct)\n            all_wave.append([samples,direct])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split WAV, Label","metadata":{}},{"cell_type":"code","source":"wav_all = np.reshape(np.delete(all_wave,1,1),(len(all_wave)))\nlabel_all = [i for i in np.delete(all_wave,0,1).tolist()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation\n\nFor data augmentation, i will mix train wav, and same length (1 second) noise (10%) from '_background_noise_'","metadata":{}},{"cell_type":"code","source":"# Random pick start point\ndef get_one_noise(noise_num = 0):\n    selected_noise = background_noise[noise_num]\n    start_idx = random.randint(0,len(selected_noise)-1-8000)\n    return selected_noise[start_idx:(start_idx+8000)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_ratio = 0.1\nnoised_wav = []\naugment = 1\ndelete_index = []\nfor i in range(augment):\n    new_wav = []\n    noise = get_one_noise(i)\n    for i,s in enumerate(wav_all):\n        if len(s)!=8000:\n            delete_index.append(i)\n            continue\n        s = s + (max_ratio*noise)\n        noised_wav.append(s)\nnp.delete(wav_all,delete_index)\nnp.delete(label_all,delete_index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wav_vals = np.array([x for x in wav_all])\nlabel_vals = [x for x in label_all]\nwav_vals.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = copy.deepcopy(label_vals)\nfor _ in range(augment):\n    label_vals = np.concatenate((label_vals,labels),axis = 0)\nlabel_vals = label_vals.reshape(-1,1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random sampling from unknown wav data","metadata":{}},{"cell_type":"code","source":"# Knowns audio random sampling\nunknown = unknown_wav\nnp.random.shuffle(unknown_wav)\nunknown = np.array(unknown)\nunknown = unknown[:2000*(augment+1)]\nunknown_label = np.array(['unknown' for _ in range(2000*(augment+1))])\nunknown_label = unknown_label.reshape(2000*(augment+1),1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## May some of the wav data has different length, so we need to delete it","metadata":{}},{"cell_type":"code","source":"delete_index = []\nfor i,w in enumerate(unknown):\n    if len(w) !=8000:\n        delete_index.append(i)\nunknown = np.delete(unknown,delete_index,axis = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Random sampling from '_background_noise_'\nRandom pick background noise","metadata":{}},{"cell_type":"code","source":"# silence audio\nsilence_wav = []\nnum_wav = (2000*(augment+1))//len(background_noise)\nfor i,_ in  enumerate(background_noise):\n    for _ in range((2000*(augment+1))//len(background_noise)):\n        silence_wav.append(get_one_noise(i))\nsilence_wav = np.array(silence_wav)\nsilence_label = np.array(['silence' for _ in range(num_wav*len(background_noise))])\nsilence_label = silence_label.reshape(-1,1)\nsilence_wav.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wav_vals = np.reshape(wav_vals,(-1,8000))\nnoised_wav = np.reshape(noised_wav,(-1,8000))\nunknown = np.reshape(unknown,(-1,8000))\nsilence_wav = np.reshape(silence_wav, (-1,8000))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check the dimension","metadata":{}},{"cell_type":"code","source":"print(wav_vals.shape)\nprint(noised_wav.shape)\nprint(unknown.shape)\nprint(silence_wav.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(label_vals.shape)\nprint(unknown_label.shape)\nprint(silence_label.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Concatenate Waves, labels","metadata":{}},{"cell_type":"code","source":"wav_vals = np.concatenate((wav_vals,noised_wav),axis = 0)\nwav_vals = np.concatenate((wav_vals,unknown),axis= 0)\nwav_vals = np.concatenate((wav_vals,silence_wav),axis= 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_vals = np.concatenate((label_vals,unknown_label),axis =0)\nlabel_vals = np.concatenate((label_vals,silence_label),axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(wav_vals))\nprint(len(label_vals))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare train test dataset","metadata":{}},{"cell_type":"code","source":"train_wav,test_wav,train_label,test_label = train_test_split(wav_vals,label_vals,test_size = 0.2,random_state = 1993,shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Parameters\nlr = 0.001\ngenerations = 20000\nnum_gens_to_wait = 250\nbatch_size = 512\ndrop_out_rate = 0.5\ninput_shape = (8000,1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For Conv1D add channel\ntrain_wav = train_wav.reshape(-1,8000,1)\ntest_wav = test_wav.reshape(-1,8000,1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_value = target_list\nlabel_value.append('unknown')\nlabel_value.append('silence')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_label_value = dict()\nfor i,l in enumerate(label_value):\n    new_label_value[l] = i\nlabel_value = new_label_value","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_value","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make Label data 'string' -> class 'num'\ntemp = []\nfor v in train_label:\n    temp.append(label_value[v[0]])\ntrain_label = np.array(temp)\n\ntemp = []\nfor v in test_label:\n    temp.append(label_value[v[0]])\ntest_label = np.array(temp)\n\n# Make label data class 'num' -> 'One hot vector'\ntrain_label = keras.utils.to_categorical(train_label,len(label_value))\ntest_label = keras.utils.to_categorical(test_label,len(label_value))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train_Wav dimension : \"+str(np.shape(train_wav)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Train_Label dimension : \"+str(np.shape(train_label)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Test_Wav dimension : \"+str(np.shape(test_wav)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Test_label dimension : \"+str(np.shape(test_label)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number Of Labels : ' + str(len(label_value)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Conv1D Model\ninput_tensor = Input(shape = (input_shape))\n\nx = layers.Conv1D(8,11,padding = 'valid',activation='relu',strides = 1)(input_tensor)\nx = layers.MaxPooling1D(2)(x)\nx = layers.Dropout(drop_out_rate)(x)\nx = layers.Conv1D(16,7,padding='valid',activation='relu',strides = 1)(x)\nx = layers.MaxPooling1D(2)(x)\nx = layers.Dropout(drop_out_rate)(x)\nx = layers.Conv1D(32,5,padding='valid',activation='relu',strides = 1)(x)\nx = layers.MaxPooling1D(2)(x)\nx = layers.Dropout(drop_out_rate)(x)\nx = layers.Conv1D(64,5,padding='valid',activation='relu',strides = 1)(x)\nx = layers.MaxPooling1D(2)(x)\nx = layers.Dropout(drop_out_rate)(x)\nx = layers.Conv1D(128,3,padding='valid',activation='relu',strides = 1)(x)\nx = layers.MaxPooling1D(2)(x)\nx = layers.Flatten()(x)\nx = layers.Dense(256,activation='relu')(x)\nx = layers.Dropout(drop_out_rate)(x)\nx = layers.Dense(128,activation='relu')(x)\nx = layers.Dropout(drop_out_rate)(x)\noutput_tensor = layers.Dense(len(label_value),activation='softmax')(x)\n\nmodel = tf.keras.Model(input_tensor,output_tensor)\n\nmodel.compile(loss = keras.losses.categorical_crossentropy,\n             optimizer = keras.optimizers.Adam(lr = lr),\n             metrics = ['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_wav, train_label, validation_data=(test_wav, test_label),\n          batch_size=batch_size, \n          epochs=100,\n          verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title(\"Model Accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.legend(['train','test'],loc = 'upper left')\nplt.show()\n\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title(\"Model Loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epoch\")\nplt.legend(['train','test'],loc = 'upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nkeras.models.save_model(model,'speech-recognition.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}